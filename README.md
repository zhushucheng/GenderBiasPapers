# Gender Bias Papers

>  Contributed by [Jishun Zhao](https://github.com/DgCtRbt) and [Shucheng Zhu](https://github.com/zhushucheng).

## Introduction

In this repo, we list some related work on gender bias. Corrections and suggestions are welcomed. 


## Contents

1. [Volume](#Volume)
2. [ArXiv's latest related papers](#ArXiv's-latest-related-papers)
3. [Review article](#Review-article)
4. [Bias analysis](#Bias-analysis)
5. [Bias measurement](#Bias-measurement)
6. [Bias Detection](#Bias-Detection)
7. [Model de-bias](#Model-de-bias)
8. [Text de-bias](#Text-de-bias)
9. [Data set](#Data-set)
10. [Conference](#Conference)
11. [Comment](#Comment )
12. [Psychology](#Psychology)
13. [Relevant literature](#Relevant-literature)
14. [Prompt](#Prompt)
15. [Group Image](#Group-Image)

## Volume

1. [Proceedings of the First Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/W19-38.pdf)
2. [Proceedings of the Second Workshop on Gender Bias in Natural Language Processing](https://www.aclweb.org/anthology/volumes/2020.gebnlp-1/)
3. [Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing](https://aclanthology.org/volumes/2021.gebnlp-1/)

## ArXiv's latest related papers

1. Back to Square One：Bias Detection, Training and Commonsense Disentanglement in the Winograd Schema.2021.[PDF](https://arxiv.org/abs/2104.08161)
2. Detoxifying Language Models Risks Marginalizing Minority Voices.2021.[PDF](https://arxiv.org/abs/2104.06390)
3. First the Worst：Finding Better Gender Translations during Beam Search.2021.[PDF](https://arxiv.org/abs/2104.07429)
4. Gender Bias in Machine Translation.2021.[PDF](https://arxiv.org/abs/2104.06001)
5. Improving Gender Translation Accuracy with Filtered Self-training.2021.[PDF](https://arxiv.org/abs/2104.07695)
6. Investigating Failures of Automatic Translation in the Case of Unambiguous Gender.2021.2021.[PDF](https://arxiv.org/abs/2104.07838)
7. Quantifying Gender Bias Towards Politicians in Cross-Lingual Language Models.2021.[PDF](https://arxiv.org/abs/2104.07505)
8. Unmasking the Mask - Evaluating Social Biases in Masked Language Models.2021. [PDF](https://arxiv.org/abs/2104.07496)
9. Revealing Persona Biases in Dialogue Systems.2021.[PDF](https://arxiv.org/abs/2104.08728)
10. Hidden Biases in Unreliable News Detection Datasets.2021.[PDF](https://arxiv.org/abs/2104.10130)
11. Identifying Offensive Expressions of Opinion in Context.2021.[PDF](https://arxiv.org/abs/2104.12227)
12. Contextual Lexicon-Based Approach for Hate Speech and Offensive Language Detection.2021.[PDF](https://arxiv.org/abs/2104.12265)
13. Impact of Gender Debiased Word Embeddings in Language Modeling.2021.[PDF](https://arxiv.org/abs/2105.00908)
14. The Authors Matter: Understanding and Mitigating Implicit Bias in Deep Text Classification.2021.[PDF](https://arxiv.org/abs/2105.02778)
15. Societal Biases in Language Generation: Progress and Challenges.2021.[PDF](https://arxiv.org/abs/2105.04054)
16. Evaluating Gender Bias in Natural Language Inference.2021.[PDF](https://arxiv.org/abs/2105.05541)
17. Multilingual Offensive Language Identification for Low-resource Languages.2021.[PDF](https://arxiv.org/abs/2105.05996)
18. Black or White but Never Neutral: How Readers Perceive Identity from Yellow or Skin-toned Emoji.2021.[PDF](https://arxiv.org/abs/2105.05887)
19. The Incel Lexicon: Deciphering the Emergent Cryptolect of a Global Misogynistic Community.2021.[PDF](https://arxiv.org/abs/2105.12006)
20. MBIC - A Media Bias Annotation Dataset Including Annotator Characteristics.2021.[PDF](https://arxiv.org/abs/2105.11910)
21. How to Split: The Effect of Word Segmentation on Gender Bias in Speech Translation.2021.[PDF](https://arxiv.org/abs/2105.13782)
22. A Simple Voting Mechanism for Online Sexist Content Identification.2021.[PDF](https://arxiv.org/abs/2105.14309)
23. LPF: A Language-Prior Feedback Objective Function for De-biased Visual Question Answering.2021.[PDF](https://arxiv.org/abs/2105.14300)
24. Gender Bias Amplification During Speed-Quality Optimization in Neural  Machine Translation.2021.[PDF](https://arxiv.org/abs/2106.00169)
25. Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese  Adjectives.2021.[PDF](https://arxiv.org/abs/2106.00181)
26. John Praised Mary Because He? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs.2021.[PDF](https://arxiv.org/abs/2106.01060)
27. Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia.2021.[PDF](https://arxiv.org/abs/2106.01601)
28. Understanding and Countering Stereotypes: A Computational Approach to  the Stereotype Content Model.2021.[PDF](https://arxiv.org/abs/2106.02596)
29. Towards Equal Gender Representation in the Annotations of Toxic Language  Detection.2021.[PDF](https://arxiv.org/abs/2106.02183)
30. A Diachronic Evaluation of Gender Asymmetry in Euphemism.2021.[PDF](https://arxiv.org/abs/2106.02083)
31. LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots.2021.[PDF](https://arxiv.org/abs/2106.02076)
32. RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models.2021.[PDF](https://arxiv.org/abs/2106.03521)
33. Automatic Sexism Detection with Multilingual Transformer Models.2021.[PDF](https://arxiv.org/abs/2106.04908)
34. Stereotype and Skew: Quantifying Gender Bias in Pre-trained and Fine-tuned Language Models.2021.EACL.[PDF](https://www.aclweb.org/anthology/2021.eacl-main.190/)
35. Ruddit: Norms of Offensiveness for English Reddit Comments.2021.[PDF](https://arxiv.org/abs/2106.05664)
36. Evaluating Gender Bias in Hindi-English Machine Translation.2021.[PDF](https://arxiv.org/abs/2106.08680)
37. Subjective Bias in Abstractive Summarization.2021.[PDF](https://arxiv.org/abs/2106.10084)
38. Predicting Gender of Brazilian Names Using Deep Learning.2021.[PDF](https://arxiv.org/abs/2106.10156)
39. A Survey of Race, Racism, and Anti-Racism in NLP.2021.[PDF](https://arxiv.org/abs/2106.11410)
40. On Positivity Bias in Negative Reviews.2021.[PDF](https://arxiv.org/abs/2106.12056)
41. Towards Understanding and Mitigating Social Biases in Language Models.2021.[PDF](https://arxiv.org/abs/2106.13219)
42. A Source-Criticism Debiasing Method for GloVe Embeddings.2021.[PDF](https://arxiv.org/abs/2106.13382)
43. Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics.2021.[PDF](https://arxiv.org/abs/2106.14574)
44. On the Interaction of Belief Bias and Explanations.2021.[PDF](https://arxiv.org/abs/2106.15355)
45. Sexism in the Judiciary.2021.[PDF](https://arxiv.org/abs/2106.15103)
46. Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning.2021.[PDF](https://arxiv.org/abs/2107.02759)
47. Generating Gender Augmented Data for NLP.2021.[PDF](https://arxiv.org/abs/2107.05987)
48. Intersectional Bias in Causal Language Models.2021.[PDF](https://arxiv.org/abs/2107.07691)
49. Using Adversarial Debiasing to Remove Bias from Word Embeddings.2021.[PDF](https://arxiv.org/abs/2107.10251)
50. Debiasing Multilingual Word Embeddings: A Case Study of Three Indian  Languages.2021.[PDF](https://arxiv.org/abs/2107.10181)
51. How Do Pedophiles Tweet? Investigating the Writing Styles and Online  Personas of Child Cybersex Traffickers in the Philippines.2021.[PDF](https://arxiv.org/abs/2107.09881)
52. Extending Challenge Sets to Uncover Gender Bias in Machine Translation: Impact of Stereotypical Verbs and Adjectives.2021.[PDF](https://arxiv.org/abs/2107.11584)
53. Context-aware Adversarial Training for Name Regularity Bias in Named Entity Recognition.2021.[PDF](https://arxiv.org/abs/2107.11610)
54. Q-Pain: A Question Answering Dataset to Measure Social Bias in Pain Management.2021.[PDF](https://arxiv.org/abs/2108.01764)
55. SWSR: A Chinese Dataset and Lexicon for Online Sexism Detection.2021.[PDF](https://arxiv.org/abs/2108.03070)
56. GENder-IT: An Annotated English-Italian Parallel Challenge Set for Cross-linguistic Natural Gender Phenomena.2021.[PDF](https://arxiv.org/abs/2108.02854)
57. What do Bias Measures Measure?.2021.[PDF](https://arxiv.org/abs/2108.03362)
58. Diachronic Analysis of German Parliamentary Proceedings: Ideological Shifts through the Lens of Political Biases.2021.[PDF](https://arxiv.org/abs/2108.06295)
59. 2020 U.S. Presidential Election: Analysis of Female and Male Users on Twitter.2021.[PDF](https://arxiv.org/abs/2108.09416)
60. Examining Covert Gender Bias: A Case Study in Turkish and English Machine Translation Models.2021.[PDF](https://arxiv.org/abs/2108.10379)
61. Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies.2021.[PDF](https://arxiv.org/abs/2108.12084)
62. A Generative Approach for Mitigating Structural Biases in Natural Language Inference.2021.[PDF](https://arxiv.org/abs/2108.14006)
63. Dataset for Identification of Homophobia and Transophobia in  Multilingual YouTube Comments.2021.[PDF](https://arxiv.org/abs/2109.00227)
64. Machine-Learning Media Bias.2021.[PDF](https://arxiv.org/abs/2109.00024)
65. Don't Discard All the Biased Instances: Investigating a Core Assumption in Dataset Bias Mitigation Techniques.2021.[PDF](https://arxiv.org/abs/2109.00521)
66. SS-BERT: Mitigating Identity Terms Bias in Toxic Comment Classification by Utilising the Notion of "Subjectivity" and "Identity Terms".2021.[PDF](https://arxiv.org/abs/2109.02691)
67. Sustainable Modular Debiasing of Language Models.2021.[PDF](https://arxiv.org/abs/2109.03646)
68. Hi, My Name Is Martha: Using Names to Measure and Mitigate Bias in Generative Dialogue Models.2021.[PDF](https://arxiv.org/abs/2109.03300)
69. Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution and Machine Translation.2021.[PDF](https://arxiv.org/abs/2109.03858)
70. Debiasing Methods in Natural Language Understanding Make Bias More Accessible.2021.[PDF](https://arxiv.org/abs/2109.04095)
71. Assessing the Reliability of Word Embedding Gender Bias Measures.2021.[PDF](https://arxiv.org/abs/2109.04732)
72. Mitigating Language-Dependent Ethnic Bias in BERT.2021.[PDF](https://arxiv.org/abs/2109.05704)
73. NeuTral Rewriter: A Rule-Based and Neural Approach to Automatic Rewriting into Gender-Neutral Alternatives.2021.[PDF](https://arxiv.org/abs/2109.06105)
74. Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search.2021.[PDF](https://arxiv.org/abs/2109.05433)
75. Uncovering Implicit Gender Bias in Narratives through Commonsense Inference.2021.[PDF](https://arxiv.org/abs/2109.06437)
76. The Emergence of the Shape Bias Results from Communicative Efficiency.2021.[PDF](https://arxiv.org/abs/2109.06232)
77. Text as Causal Mediators: Research Design for Causal Estimates of Differential Treatment of Social Groups via Language Aspects.2021.[PDF](https://arxiv.org/abs/2109.07542)
78. Balancing out Bias: Achieving Fairness Through Training Reweighting.2021.[PDF](https://arxiv.org/abs/2109.08253)
79. Model Bias in NLP - Application to Hate Speech Classification.2021.[PDF](https://arxiv.org/abs/2109.09725)
80. A Machine Learning Pipeline to Examine Political Bias with Congressional Speeches.2021.[PDF](https://arxiv.org/abs/2109.09014)
81. UPV at CheckThat! 2021: Mitigating Cultural Differences for Identifying Multilingual Check-worthy Claims.2021.[PDF](https://arxiv.org/abs/2109.09232)
82. Stepmothers Are Mean and Academics Are Pretentious: What Do Pretrained Language Models Learn about You?.2021.[PDF](https://arxiv.org/abs/2109.10052)
83. Contrastive Learning for Fair Representations.2021.[PDF](https://arxiv.org/abs/2109.10645)
84. Fairness-aware Class Imbalanced Learning.2021.[PDF](https://arxiv.org/abs/2109.10444)
85. Evaluating Debiasing Techniques for Intersectional Biases.2021.[PDF](https://arxiv.org/abs/2109.10441)
86. Can Question Generation Debias Question Answering Models? A Case Study on Question-context Lexical Overlap.2021.[PDF](https://arxiv.org/abs/2109.11256)
87. Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender.2021.[PDF](https://arxiv.org/abs/2109.11061)
88. Detect and Perturb: Neutral Rewriting of Biased and Sensitive Text via Gradient-based Decoding.2021.[PDF](https://arxiv.org/abs/2109.11708)
89. Mitigating Racial Biases in Toxic Language Detection with an Equity-based Ensemble Framework.2021.[PDF](https://arxiv.org/abs/2109.13137)
90. How Different Text-preprocessing Techniques Using The BERT Model Affect The Gender Profiling of Authors.2021.[PDF](https://arxiv.org/abs/2109.13890)
91. VoxCeleb Enrichment for Age and Gender Recognition.2021.[PDF](https://arxiv.org/abs/2109.13510)
92. Identifying and Mitigating Gender Bias in Hyperbolic Word Embeddings.2021.[PDF](https://arxiv.org/abs/2109.13767)
93. Marked Attribute Bias in Natural Language Inference.2021.[PDF](https://arxiv.org/abs/2109.14039)
94. Second Order WinoBias (SoWinoBias) Test Set for Latent Gender Bias Detection in Coreference Resolution.2021.[PDF](https://arxiv.org/abs/2109.14047)
95. #ContextMatters: Advantages and Limitations of Using Machine Learning to Support Women in Politics.2021.[PDF](https://arxiv.org/abs/2110.00116)
96. Unpacking the Interdependent Systems of Discrimination: Ableist Bias in NLP Systems through an Intersectional Lens.2021.[PDF](https://arxiv.org/abs/2110.00521)
97. Adversarial Examples Generation for Reducing Implicit Gender Bias in Pre-trained Models.2021.[PDF](https://arxiv.org/abs/2110.01094)
98. Low Frequency Names Exhibit Bias and Overfitting in Contextualizing Language Models.2021.[PDF](https://arxiv.org/abs/2110.00672)
99. Representation of Professions in Entertainment Media: Insights into Frequency and Sentiment Trends through Computational Text Analysis.2021.[PDF](https://arxiv.org/abs/2110.03873)
100. Evaluation of Summarization Systems across Gender, Age, and Race.2021.[PDF](https://arxiv.org/abs/2110.04384)
101. Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting.2021.[PDF](https://arxiv.org/abs/2110.05367)
102. BBQ: A Hand-Built Bias Benchmark for Question Answering.2021.[PDF](https://arxiv.org/abs/2110.08193)
103. Don't Speak Too Fast: The Impact of Data Bias on Self-supervised Speech Models.2021.[PDF](https://arxiv.org/abs/2110.07957)
104. Socially Aware Bias Measurements for Hindi Language Representations.2021.[PDF](https://arxiv.org/abs/2110.07871)
105. The World of an Octopus: How Reporting Bias Influences a Language Model's Perception of Color.2021.[PDF](https://arxiv.org/abs/2110.08182)
106. Don't Judge Me by My Face: An Indirect Adversarial Approach to Remove Sensitive Information From Multimodal Neural Representation in Asynchronous Job Video Interviews.2021.[PDF](https://arxiv.org/abs/2110.09424)
107. The Arabic Parallel Gender Corpus 2.0: Extensions and Analyses.2021.[PDF](https://arxiv.org/abs/2110.09216)
108. An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models.2021.[PDF](https://arxiv.org/abs/2110.08527)
109. AequeVox: Automated Fairness Testing of Speech Recognition Systems.2021.[PDF](https://arxiv.org/abs/2110.09843)
110. Hate Speech Classifiers Learn Human-like Social Stereotypes.2021.[PDF](https://arxiv.org/abs/2110.14839)
111. Transformer Ensembles for Sexism Detection.2021.[PDF](https://arxiv.org/abs/2110.15905)
112. Detecting Gender Bias in Transformer-based Models: A Case Study on BERT.2021.[PDF](https://arxiv.org/abs/2110.15733)
113. Deep Learning for Bias Detection: From Inception to Deployment.2021.[PDF](https://arxiv.org/abs/2110.15728)
114. The Golden Rule as a Heuristic to Measure the Fairness of Texts Using Machine Learning.2021.[PDF](https://arxiv.org/abs/2111.00107)
115. Measuring a Texts Fairness Dimensions Using Machine Learning Based on Social Psychological Factors.2021.[PDF](https://arxiv.org/abs/2111.00086)
116. Sexism Identification in Tweets and Gabs using Deep Neural Networks.2021.[PDF](https://arxiv.org/abs/2111.03612)
117. Words of Wisdom: Representational Harms in Learning From AI Communication.2021.[PDF](https://arxiv.org/abs/2111.08581)
118. Assessing gender bias in medical and scientific masked language models with StereoSet.2021.[PDF](https://arxiv.org/abs/2111.08088)
119. Contrastive Clustering: Toward Unsupervised Bias Reduction for Emotion and Sentiment Classification.2021.[PDF](https://arxiv.org/abs/2111.07448)
120. Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection.2021.[PDF](https://arxiv.org/abs/2111.07997)
121. Evaluating Metrics for Bias in Word Embeddings.2021.[PDF](https://arxiv.org/abs/2111.07864)
122. Investigating Cross-Linguistic Gender Bias in Hindi-English Across Domains.2021.[PDF](https://arxiv.org/abs/2111.11159)
123. The ComMA Dataset V0.2: Annotating Aggression and Bias in Multilingual Social Media Discourse.2021.[PDF](https://arxiv.org/abs/2111.10390)
124. Identification of Bias Against People with Disabilities in Sentiment Analysis and Toxicity Detection Models.2021.[PDF](https://arxiv.org/abs/2111.13259)
125. raceBERT -- A Transformer-based Model for Predicting Race from Names.2021.[PDF](https://arxiv.org/abs/2112.03807)
126. Reducing Target Group Bias in Hate Speech Detectors.2021.[PDF](https://arxiv.org/abs/2112.03858)
127. Ethical and Social Risks of Harm from Language Models.2021.[PDF](https://arxiv.org/abs/2112.04359)
128. Word Embeddings via Causal Inference: Gender Bias Reducing and Semantic Information Preserving.2021.[PDF](https://arxiv.org/abs/2112.05194)
129. Towards A Reliable Ground-truth For Biased Language Detection.2021.[PDF](https://arxiv.org/abs/2112.07421)
130. Identification of Biased Terms in News Articles by Comparison of Outlet-specific Word Embeddings.2021.[PDF](https://arxiv.org/abs/2112.07384)
131. Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in Pretrained Language Models.2021.[PDF](https://arxiv.org/abs/2112.07447)
132. Do You Think It's Biased? How To Ask For The Perception Of Media Bias.2021.[PDF](https://arxiv.org/abs/2112.07392)
133. Few-shot Instruction Prompts for Pretrained Language Models to Detect Social Biases.2021.[PDF](https://arxiv.org/abs/2112.07868)
134. Analyzing the Limits of Self-Supervision in Handling Bias in Language.2021.[PDF](https://arxiv.org/abs/2112.08637)
135. Gendered Language in Resumes and its Implications for Algorithmic Bias in Hiring.2021.[PDF](https://arxiv.org/abs/2112.08910)
136. Automatically Identifying Semantic Bias in Crowdsourced Natural Language Inference Datasets.2021.[PDF](https://arxiv.org/abs/2112.09237)
137. Improving Ethical Outcomes with Machine-in-the-Loop: Broadening Human Understanding of Data Annotations.2021.[PDF](https://arxiv.org/abs/2112.09738)
138. LUC at ComMA-2021 Shared Task: Multilingual Gender Biased and Communal Language Identification without Using Linguistic Features.2021.[PDF](https://arxiv.org/abs/2112.10189)
139. Quantifying Gender Biases Towards Politicians on Reddit.2021.[PDF](https://arxiv.org/abs/2112.12014)
140. An Interdisciplinary Approach for the Automated Detection and Visualization of Media Bias in News Articles.2021.[PDF](https://arxiv.org/abs/2112.13352)
141. Hypers at ComMA@ICON: Modelling Aggressiveness, Gender Bias and Communal Bias Identification.2022.[PDF](https://arxiv.org/abs/2112.15417)
142. AI & Racial Equity: Understanding Sentiment Analysis Artificial Intelligence, Data Security, and Systemic Theory in Criminal Justice Systems.2022.[PDF](https://arxiv.org/abs/2201.00855)
143. Quantifying Gender Bias in Consumer Culture.2022.[PDF](https://arxiv.org/abs/2201.03173)
144. Unintended Bias in Language Model-drivenConversational Recommendation.2022.[PDF](https://arxiv.org/abs/2201.06224)
145. Gender Bias in Text: Labeled Datasets and Lexicons.2022.[PDF](https://arxiv.org/abs/2201.08675)
146. Regional Negative Bias in Word Embeddings Predicts Racial Animus - But Only via Name Frequency.2022.[PDF](https://arxiv.org/abs/2201.08451)

## Review article

1. The Psychology of Prejudice, Stereotyping and Discrimination: An Overview.2003.[PDF](https://www.simplypsychology.org/Prejudice.pdf)
2. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[PDF](https://arxiv.org/abs/1906.08976v1)
3. Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview.2020.[PDF](https://arxiv.org/abs/1912.11078)
4. Language (Technology) is Power: A Critical Survey of “Bias” in NLP.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.485/)
5. Societal Biases in Language Generation: Progress and Challenges.2021.ACL.[PDF](https://arxiv.org/abs/2105.04054)
6. Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in Pretrained Language Models.2021.[PDF](https://arxiv.org/abs/2112.07447)
7. An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-Trained Language Models.2021.[PDF](https://arxiv.org/abs/2110.08527)
8. A Survey on Gender Bias in Natural Language Processing.2021.[PDF](https://arxiv.org/abs/2112.14168)


## Bias analysis

1. Man Is to Computer Programmer as Woman Is to Homemaker? Debiasing Word Embeddings.2016.[PDF](https://arxiv.org/abs/1607.06520)
2. Gender Bias and Sexism in Language.2017.[PDF](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470#acrefore-9780190228613-e-470-div1-8)
3. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints.2017.EMNLP(Best Long Paper).[PDF](https://arxiv.org/pdf/1707.09457.pdf)
4. Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes.2018.[PDF](https://arxiv.org/abs/1711.08412v1).[Code](https://github.com/nikhgarg/EmbeddingDynamicStereotypes)
5. Understanding the Origins of Bias in Word Embeddings.2018.[PDF](https://arxiv.org/abs/1810.03611)
6. Is there Gender bias and stereotype in Portuguese Word Embeddings?.2018.[PDF](https://arxiv.org/abs/1810.04528)
7. Learning Gender-Neutral Word Embeddings.2018.EMNLP.[PDF](https://arxiv.org/abs/1809.01496v1)
8. Measuring Societal Biases from Text Corpora with Smoothed First-Order Co-occurrence.2018.[PDF](https://arxiv.org/abs/1812.10424)
9. Measuring and Mitigating Unintended Bias in Text Classification.2018.AAAI.[PDF](https://dl.acm.org/doi/pdf/10.1145/3278721.3278729)
10. Gender Bias in Sentiment Analysis.2018.[PDF](https://wlv.openrepository.com/bitstream/handle/2436/620633/GenderBiasInSentimentAnalysisPreprint.pdf?sequence=9&isAllowed=y)
11. Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems.2018.[PDF](https://arxiv.org/abs/1805.04508)
12. Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis.2019.[PDF](https://arxiv.org/abs/1906.10256v2)
13. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
14. Evaluating the Underlying Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.08783)
15. Measuring Bias in Contextualized Word Representations.2019.[PDF](https://arxiv.org/abs/1906.07337v1)
16. Examining the Presence of Gender Bias in Customer Reviews Using Word Embedding.2019.[PDF](https://arxiv.org/abs/1902.00496v1)
17. Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990.2019.[PDF](https://www.aclweb.org/anthology/W19-4712/)
18. How Does Grammatical Gender Affect Noun Representations in Gender-Marking Languages?.2019.[PDF](https://arxiv.org/pdf/1910.14161.pdf)
19. Quantifying the Semantic Core of Gender Systems.2019.EMNLP.[PDF](https://arxiv.org/pdf/1910.13497.pdf)
20. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019.[PDF](https://www.aclweb.org/anthology/D19-1176/)
21. Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis.2019.ACL.[PDF](https://www.aclweb.org/anthology/W19-3803/)
22. Towards Understanding Gender Bias in Neural Relation Extraction.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.265/)
23. Investigating Potential Factors Associated with Gender Discrimination in Collaborative Recommender Systems.2020.[PDF](https://arxiv.org/abs/2002.07786)
24. Analyzing Gender Bias within Narrative Tropes.2020.[PDF](https://arxiv.org/pdf/2011.00092.pdf)


## Bias measurement

1. Measuring Individual Differences in Implicit Cognition: The Implicit Association Test.1998.[PDF](https://groups.psych.northwestern.edu/rosenfeld/documents/greenwald98IAT.pdf)
2. National Differences in Gender–science Stereotypes Predict National Sex Differences in Science and Math Achievement.2009.PNAS.[PDF](https://www.pnas.org/content/pnas/106/26/10593.full.pdf)
3. First Women, Second Sex: Gender Bias in Wikipedia.2015.[PDF](https://arxiv.org/abs/1502.02341)
4. It's A Man's Wikipedia? Assessing Gender Inequality in An Online Encyclopedia.2015.[PDF](https://arxiv.org/abs/1501.06307)
5. Social Bias in Elicited Natural Language Inference.2017.[PDF](https://www.aclweb.org/anthology/W17-1609.pdf)
6. Semantics Derived Automatically from Language Corpora Contain Human-like Biases.2017.[PDF](https://arxiv.org/abs/1608.07187)
7. Gender Bias in Neural Natural Language Processing.2018.[PDF](https://arxiv.org/abs/1807.11714)
8. Reducing Gender Bias in Abusive Language Detection.2018.[PDF](https://arxiv.org/abs/1808.07231)
9. Gender Bias in Coreference Resolution.2018.[PDF](https://arxiv.org/abs/1804.09301)
10. Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns.2018.[PDF](https://watermark.silverchair.com/tacl_a_00240.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqkwggKlBgkqhkiG9w0BBwagggKWMIICkgIBADCCAosGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMPE7Kg3Ht5MYve550AgEQgIICXP0XeqeYbNwTfeu-j1c7Q84pHmZAqEziDs0r7WXaeGBx5LZkRmuTp5wWdWdxFj1tqwjN3l74QyTiz7PiN066qi2gOOvAqATNT07KTu5y-R-2SPSD_ExZBGdkKDnkyGm3zIXwJ7zx7FC78Ud5b-2c5LdYNC7dyBd_4Te-ca3hwUzilZqAezF-IwBTrPTt5to0M-B10aAfHCjgxQRxui_cTtS20pDtnQEor6G9vhZwF9ckwVb47CYSqt4qoL1jDuBMTRuRiKBnr7Qp2pI6YLfRz7gtaB6plzaU_3i6tWXcO4HHPx7K3o0JbJAREUSQ3R9PAPyuUCihdQ6LtxHKRL8QEbZ5rsjSqa4_KgFDgsF7R1gycfsS1g0opxrLXQKpLrZ4ZrQTODPubSewo1Bl0jw_Yy9kKTTYCrrboEQZpwR1f7wThslo5PrykUlIwf-usJ_VP2z1ysV7wZWKQ7jYt7whsj1RNBfnn5JmwGZIOeGSvybhrfipV3qQ1LkiN1vn3XytCY9kYgohgcPyQuZWa4kAVKN5_Un32s3Ijc-7pY8y4MlA-HRfw4IZkpNpKQI2PMGThZZ2RWjJDW7z1mWvKc3-DLH_pRs56OwVTMUEYh5DoCjl57UxLgK9fhVgQGGhlpzQflDCkM-381s_j0KJV-R2aVucdagpOBNlKPriqdH3SCvvw60TEtNH9uALDxpd8AONrOXvOkW3zQvgbni-96SzWcGr6lEfVFo5g5wf8pDnMhYNVfmGEHJ476lMFdwdzaolMJ360aAGMx2s96rDmEl1EQxsSObYhfDFx1H00fo)
11. Toward Gender-inclusive Coreference Resolution.2019.[PDF](https://arxiv.org/abs/1910.13913)
12. Measuring Bias in Contextualized Word Representations.2019.[PDF](https://arxiv.org/abs/1906.07337)
13. Assessing Social and Intersectional Biases in Contextualized Word Representations.2019.NIPS.[PDF](https://arxiv.org/abs/1911.01485)
14. Measuring Gender Bias in Word Embeddings across Domains and Discovering New Gender Bias Word Categories.2019.[PDF](https://www.aclweb.org/anthology/W19-3804.pdf)
15. On Measuring Social Biases in Sentence Encoders.2019.[PDF](https://arxiv.org/abs/1903.10561)
16. Black Is to Criminal as Caucasian Is to Police: Detecting and Removing Multiclass Bias in Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.04047)
17. Lipstick on A Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings but Do Not Remove Them.2019.[PDF](https://arxiv.org/abs/1903.03862)
18. Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts.2019.[PDF](https://www.aclweb.org/anthology/D19-1176.pdf)
19. StereoSet: Measuring stereotypical bias in pretrained language models.2020.[PDF](https://arxiv.org/abs/2004.09456v1)

## Bias Detection
1. Automatic recognition of habituals: a three-way classification of clausal aspect.2015.EMNLP.[PDF](https://aclanthology.org/D15-1294.pdf)
2. Identifying Generic Noun Phrases.2015.[PDF](https://aclanthology.org/P10-1005.pdf)
3. Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations.2017.[PDF](https://aclanthology.org/W17-3014.pdf)
4. Identifying Semantic Edit Intentions from Revisions in Wikipedia.2017.[PDF](https://www.aclweb.org/anthology/D17-1213.pdf)
5. Detecting Biased Statements in Wikipedia.2018.[PDF](https://www.researchgate.net/profile/Besnik-Fetahu-2/publication/324641488_Detecting_Biased_Statements_in_Wikipedia/links/5b7d1b2592851c1e1226bd86/Detecting-Biased-Statements-in-Wikipedia.pdf)
6. Neural Based Statement Classification for Biased Language.2018.[PDF](https://arxiv.org/pdf/1811.05740.pdf)
7. Identifying Framing Bias in Online News.2018.[PDF](https://dl.acm.org/doi/pdf/10.1145/3204948)
8. Unsupervised Discovery of Implicit Gender Bias.2020.EMNLP.[PDF](https://arxiv.org/abs/2004.08361)
9. CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models.EMNLP 2020.[PDF](https://arxiv.org/abs/2010.00133)


## Model de-bias

1. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter.2016.[PDF](https://www.aclweb.org/anthology/N16-2013.pdf)
2. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods.2018.NAACL.[PDF](https://arxiv.org/abs/1804.06876v1)
3. Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies.2018.[PDF](http://proceedings.mlr.press/v81/madaan18a/madaan18a.pdf)
4. Learning Gender-Neutral Word Embeddings.2018.EMNLP.[PDF](https://arxiv.org/abs/1809.01496v1)
5. Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior.2018.[PDF](https://arxiv.org/abs/1802.00393)
6. Mitigating Unwanted Biases with Adversarial Learning.2018.[PDF](https://arxiv.org/abs/1801.07593)
7. The Knowref Coreference Corpus: Removing Gender and Number Cues for Difficult Pronominal Anaphora Resolution.2018.[PDF](https://arxiv.org/abs/1811.01747)
8. Mitigating Gender Bias in Natural Language Processing: Literature Review.2019.[PDF](https://arxiv.org/abs/1906.08976v1)
9. Gender Bias in Contextualized Word Embeddings.2019.[PDF](https://arxiv.org/abs/1904.03310)
10. It's All in the Name: Mitigating Gender Bias with Name-Based Counterfactual Data Substitution.2019.[PDF](https://arxiv.org/abs/1909.00871v3)
11. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.2019.ACL.[PDF](https://arxiv.org/abs/1906.04571)
12. Getting Gender Right in Neural Machine Translation.2019.[PDF](https://arxiv.org/abs/1909.05088)
13. Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques.2019.[PDF](https://arxiv.org/abs/1901.03116)
14. Filling Gender & Number Gaps in Neural Machine Translation with Black-box Context Injection.2019.[PDF](https://arxiv.org/abs/1903.03467)
15. Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function.2019.[PDF](https://arxiv.org/abs/1905.12801)
16. The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations.2019.ACL.[PDF](https://www.aclweb.org/anthology/W19-3808/)
17. Conceptor Debiasing of Word Representations Evaluated on WEAT.2019.[PDF](https://arxiv.org/abs/1906.05993)
18. Gender-preserving Debiasing for Pre-trained Word Embeddings.2019.[PDF](https://arxiv.org/abs/1906.00742)
19. Examining Gender Bias in Languages with Grammatical Gender.2019.EMNLP.[PDF](https://arxiv.org/abs/1909.02224)
20. Generating Clues for Gender based Occupation De-biasing in Text.2019.[PDF](https://arxiv.org/abs/1804.03839)
21. Women, Politics and Twitter: Using Machine Learning to Change the Discourse.2019.[PDF](https://arxiv.org/abs/1911.11025) 
22. Resolving Gendered Ambiguous Pronouns with BERT.2019.[PDF](https://arxiv.org/abs/1906.01161)
23. Transfer Learning from Pre-trained BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3812/)
24. On GAP Coreference Resolution Shared Task: Insights from the 3rd Place Solution.2019.[PDF](https://www.aclweb.org/anthology/W19-3816/)
25. Gendered Pronoun Resolution Using BERT and an Extractive Question Answering Formulation.2019.[PDF](https://arxiv.org/abs/1906.03695)
26. BERT Masked Language Modeling for Co-reference Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3811/)
27. Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1905.08868)
28. MSnet:A BERT-based Network for Gendered Pronoun Resolution.2019.[PDF](https://arxiv.org/abs/1908.00308)
29. Fill the GAP: Exploiting BERT for Pronoun Resolution.2019.[PDF](https://www.aclweb.org/anthology/W19-3815/)
30. Anonymized BERT: An Augmentation Approach to the Gendered Pronoun Resolution Challenge.2019.[PDF](https://arxiv.org/abs/1905.01780)
31. Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling.2019.[PDF](https://arxiv.org/abs/1906.00839)
32. Towards Understanding Gender Bias in Neural Relation Extraction.2020.ACL.[PDF](https://www.aclweb.org/anthology/2020.acl-main.265/) 
33. Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem.2020.ACL.[PDF](https://arxiv.org/abs/2004.04498)
34. A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations.2020.AAAI.[PDF](https://arxiv.org/abs/1911.10787)
35. Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation.2020.ACL.[PDF](https://arxiv.org/abs/2005.00965)
36. Mitigating Media Bias through Neutral Article Generation.2021.[PDF](https://arxiv.org/pdf/2104.00336.pdf)
37. Mitigating Political Bias in Language Models Through Reinforced Calibration.2021.AAAI.(Best Paper).[PDF](https://arxiv.org/abs/2104.14795)
38. Debiasing Pre-trained Contextualised Embeddings.2021.[PDF](https://arxiv.org/abs/2101.09523)
39. UnQovering Stereotyping Biases via Underspecified Questions.Findings of EMNLP 2020.[PDF](https://arxiv.org/abs/2010.02428)



## Text de-bias

1. When He Doesn’t Mean You: GenderExclusive Language as Ostracism.2011.[PDF](https://www.wgalil.ac.il/files/GENDER/gendered_language_ostracism.pdf)
2. Can Gender Fair Language Reduce Gender Stereotyping and Discrimination?.2016.[HTML](https://www.frontiersin.org/articles/10.3389/fpsyg.2016.00025/full)
3. Connotation Frames of Power and Agency in Modern Films.2017.[PDF](https://www.aclweb.org/anthology/D17-1247/)
4. Style Transfer Through Back-Translation.2018.[PDF](https://www.aclweb.org/anthology/P18-1080/)
5. Proposed Taxonomy for Gender Bias in Text;A Filtering Methodology for the Gender Generalization Subtype.2019.[PDF](https://www.aclweb.org/anthology/W19-3802.pdf)
6. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[PDF](https://arxiv.org/abs/1911.03842)
7. Contextual Affective Analysis: A Case Study of People Portrayals in Online #MeToo Stories.2019.[PDF](https://arxiv.org/pdf/1904.04164.pdf)
8. Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation.2019.[PDF](https://arxiv.org/abs/1911.03842)
9. Automatic Gender Identification and Reinflection in Arabic.2019.[PDF](https://www.aclweb.org/anthology/W19-3822.pdf)
10. Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology.2019.ACL.[PDF](https://www.aclweb.org/anthology/P19-1161/)
11. Multi-Dimensional Gender Bias Classification.2020.[PDF](https://arxiv.org/pdf/2005.00614.pdf)
12. Automatically Neutralizing Subjective Bias in Text.2020.AAAI.[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/5385)
13. DivGAN: Towards Diverse Paraphrase Generation via Diversified Generative Adversarial Network.2020.[PDF](https://www.aclweb.org/anthology/2020.findings-emnlp.218/)
14. PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction.2020.[PDF](https://arxiv.org/abs/2010.13816)
15. Plug and Play Language Models: A Simple Approach to Controlled Text Generation.2020.[PDF](https://arxiv.org/abs/1912.02164)
16. Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP.2021.[PDF](https://arxiv.org/pdf/2103.00453.pdf)
17. They, Them, Theirs: Rewriting with Gender-Neutral English.2021.[PDF](https://arxiv.org/pdf/2102.06788.pdf)
18. Challenges in Automated Debiasing for Toxic Language Detection.2021.EACL.[PDF](https://arxiv.org/abs/2102.00086)
19. Generate, Prune, Select: A Pipeline for Counterspeech Generation against Online Hate Speech.2021.ACL.[PDF](https://arxiv.org/abs/2106.01625)

## Data set

1. Detecting Hate Speech on the World Wide Web.2012.[PDF](https://aclanthology.org/W12-2103.pdf)
2. Automated Dictionary Creation for Analyzing Text: An Illustration from Stereotype Content.2019.[PDF](https://psyarxiv.com/afm8k/)
3. Comprehensive stereotype content dictionaries using a semi-automated method.2020.[PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1002/ejsp.2724)
4. GeBioToolkit: Automatic Extraction of Gender-Balanced Multilingual Corpus of Wikipedia Biographies.2020.[PDF](https://arxiv.org/abs/1912.04778v1)
5. Social Bias Frames: Reasoning about Social and Power Implications of Language.2020.[PDF](https://arxiv.org/abs/1911.03891)
6. StereoSet: Measuring Stereotypical Bias in Pretrained Language Models.2020.[PDF](https://arxiv.org/abs/2004.09456v1)
7. BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation.2021.[PDF](https://arxiv.org/pdf/2101.11718.pdf)
8. Ruddit: Norms of Offensiveness for English Reddit Comments.ACL 2021.[PDF](https://arxiv.org/abs/2106.05664)


## Conference
### **ACL 2021** Papers

1. [Mitigating Bias in Session-based Cyberbullying Detection: A Non-Compromising Approach](https://aclanthology.org/2021.acl-long.168.pdf)
2. [Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model](https://aclanthology.org/2021.acl-long.50.pdf)
3. [Bad Seeds: Evaluating Lexical Methods for Bias Measurement](https://aclanthology.org/2021.acl-long.148.pdf)
4. [Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction](https://aclanthology.org/2021.acl-long.261.pdf)
5. [Societal Biases in Language Generation: Progress and Challenges](https://aclanthology.org/2021.acl-long.330.pdf)
6. [De-biasing Distantly Supervised Named Entity Recognition via Causal Intervention](https://aclanthology.org/2021.acl-long.371.pdf)
7. [StereoSet: Measuring stereotypical bias in pretrained language models](https://aclanthology.org/2021.acl-long.416.pdf)
8. [Counterfactual Inference for Text Classification Debiasing](https://aclanthology.org/2021.acl-long.422.pdf)
9. [Gender bias amplification during Speed-Quality optimization in Neural Machine Translation](https://aclanthology.org/2021.acl-short.15.pdf)
10. [On Positivity Bias in Negative Reviews](https://aclanthology.org/2021.acl-short.39.pdf)
11. [Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia](https://aclanthology.org/2021.acl-short.45.pdf)
12. [Using Adversarial Attacks to Reveal the Statistical Bias in Machine Reading Comprehension Models](https://aclanthology.org/2021.acl-short.43.pdf)
13. [Personal Bias in Prediction of Emotions Elicited by Textual Opinions

#### Morality and natural language processing
1. Ruddit: Norms of Offensiveness for English Reddit Comments
2. Learning Language and Multimodal Privacy-Preserving Markers of Mood from Mobile Data
3. A Human-machine Collaborative Framework for Evaluating Malevolence in Dialogues
4. Structurizing Misinformation Stories via Rationalizing Fact-Checks
5. Mitigating Bias in Session-based Cyberbullying Detection: A Non-Compromising Approach
6. Can Sequence-to-Sequence Models Crack Substitution Ciphers?
7. Societal Biases in Language Generation: Progress and Challenges
8. Controversy and Conformity: from Generalized to Personalized Aggressiveness Detection
9. Bad Seeds: Evaluating Lexical Methods for Bias Measurement
10. Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model
11. A Survey of Race, Racism, and Anti-Racism in NLP
12. Examining the Inductive Bias of Neural Language Models with Artificial Languages
13. Changing the World by Changing the Data
14. Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets
15. Breaking Down Walls of Text: How Can NLP Benefit Consumer Privacy?
16. StereoSet: Measuring stereotypical bias in pretrained language models
17. Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy Policies
18. Intrinsic Bias Metrics Do Not Correlate with Application Bias
19. [Annotating Online Misogyny](https://aclanthology.org/2021.acl-long.247/)

### EMNLP
1. Men Also Like Shopping: Reducing Gender Bias Amplification Using Corpus-level Constraints.2017.[PDF](https://arxiv.org/pdf/1707.09457.pdf)
2. De-Biased Court’s View Generation with Causality.2020.[PDF](https://www.aclweb.org/anthology/2020.emnlp-main.56)

#### 2021
1. GFST: Gender-Filtered Self-Training for More Accurate Gender in Translation.
2. Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender.
3. Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies.
4. Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search.
5. Identifying Morality Frames in Political Tweets using Relational Learning.
6. Mitigating Language-Dependent Ethnic Bias in BERT.
7. How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs?
8. Latent Hatred: A Benchmark for Understanding Implicit Hate Speech.
9. Inducing Stereotypical Character Roles from Plot Structure
10. "Be nice to your wife! The restaurants are closed": Can Gender Stereotype Detection Improve Sexism Classification?

## Comment 

1. Gender Bias and Sexism in Language.Oxford Research Encyclopedia of Communication.2017.[PDF](https://oxfordre.com/communication/view/10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-470)
2. AI Can Be Sexist and Racist—It’s Time to Make It Fair.2018.Nature.[PDF](https://www.nature.com/articles/d41586-018-05707-8)

## Psychology

1. 偏见、歧视与刻板印象，有什么不一样?.[HTML](https://www.jianshu.com/p/b5c6465a9b73)
2. Implicit Bias: What It Means and How It Affects Behavior.[HTML](https://www.thoughtco.com/understanding-implicit-bias-4165634)

## Relevant literature

1. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.2020.[PDF](https://jmlr.org/papers/v21/20-074.html)


## Prompt
1. Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.2021.EACL.[PDF](https://arxiv.org/abs/2001.07676)
2. It’s not just size that matters: Small language models are also few-shot learners.2021.NAACL.[PDF](https://arxiv.org/abs/2009.07118)
3. Making Pre-trained Language Models Better Few-shot Learners.2021.ACL.[PDF](https://arxiv.org/abs/2012.15723)


## [Group Image](https://github.com/DgCtRbt/Group-Image)
1. Social Identity Theory.1979.[HTML](http://www.age-of-the-sage.org/psychology/social/social_identity_theory.html)
2. Narrative Language as an Expression of Individual and Group Identity: The Narrative Categorical Content Analysis.2013.[PDF](https://journals.sagepub.com/doi/pdf/10.1177/2158244013492084)



## MY LIST
1. Detecting Gender Stereotypes: Lexicon vs. Supervised Learning Methods.2020.ACM.[PDF](https://dl.acm.org/doi/abs/10.1145/3313831.3376488)
2. Implicitly Abusive Language – What does it actually look like and why are we not getting there?2021.NAACL.[PDF](https://www.aclweb.org/anthology/2021.naacl-main.48/)



